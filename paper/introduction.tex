\section{Introduction}
%The Message Passing Interface (MPI) is widely used in high performance computing (HPC). A common problem in any MPI program, is communication deadlock. A communication deadlock is ``\emph{a situation in which each member process of the group is waiting for some member process to communicate with it, but no member is attempting to communicate with it}" \cite{DBLP:conf/fsttcs/Natarajan84}. This paper refers to a communication deadlock as deadlock. 

The Message Passing Interface (MPI) is widely used in high performance computing (HPC). 
There are many features supported by MPI 3.1 standard \cite{mpi3.1}. In a brief summary, one-sided communication allows remote memory access (RMA) in MPI programs. MPI provides message passing in a point-to-point way or in a collective way. Hybrid programming with threads uses multi-threads within a process. Hybrid programming with shared memory allows a process to allocate shared memory through MPI. Also, MPI can create topology for processes and connects these processes by neighborhood collectives.  

The scope of this presentation relies on two aspects of the MPI standard: point-to-point communication and collective communication. This presentation addresses the key API calls for point-to-point communication, including blocking send and receive, non-blocking send and receive, and wait and test for witnessing the completion of the non-blocking operations. Note that the point-to-point communication may also allow the request object for non-blocking operations to be deallocated, the incoming messages to be checked, and the pending non-blocking operations to be cancelled. 
Further, this presentation addresses the collective communication. Since the barrier is typical in collective communication as the way it uses for program synchronization is the same with the other collective operations (only the other operations apply additional global functions for computation), this presentation takes barrier as an example in the following discussion.

A common problem in any MPI program using only point-to-point operations and collective operations is deadlock. The deadlock problem for a single-path MPI program is NP--Complete \cite{DBLP:conf/fm/ForejtKNS14}.
This presentation considers only single-path MPI programs that are typical of many HPC applications and are the standard for most deadlock analysis tools. 

Deadlock in a single-path MPI program is difficult to detect for several reasons. First, message races, intended or not, lead to non-determinism because a receive may be matched with more than one send by the runtime. Second, the collective operations, such as barriers, synchronize a program in complex ways leading to unexpected behaviors. And finally, the two buffering semantics, infinite buffer (messages are buffered in the system) and zero buffer (no buffering in the system), lead to different runtime behaviors. All of these aspects make testing and debugging for deadlock very difficult. 

There are several solutions proposed for deadlock detection. The \emph{match pair} based analyses do not scale to large programs \cite{DBLP:conf/ppopp/VakkalankaSGK08, DBLP:conf/sbmf/SharmaGB12, DBLP:conf/fm/ForejtKNS14}. A match pair consists of a send and a receive that may potentially match in the runtime. The number of match pair resolutions may be massive for a large program.
There are also static analysis based solutions that are able to scale \cite{DBLP:conf/sc/SharmaGB12, DBLP:conf/pldi/JoshiPSN09, Subodh:Dissertation}. These solutions start with a set of potential deadlocks that can be efficiently detected, and then predict real deadlocks from the set using static analysis.
The general algorithm in this presentation is inspired by such work.

This presentation presents a new algorithm that is able to detect a deadlock for a single-path MPI program in three steps. 
The input trace program is initialized by executing the program once.
The algorithm first uses a static analyzer to detect a set of deadlock pattern instances by statically traversing the program and matching patterns in the program text. The algorithm then uses an abstract machine to prune provably non-feasible pattern instances from the set of potential deadlocks. If needed, the algorithm finally validates whether or not any remaining instances imply a real deadlock. Novel in the approach is the abstract machine that efficiently rejects non-feasible instances by simply counting the issued sends and receives, instead of exhaustively enumerating all message races. The complexity of the abstract machine is quadratic in the number of communications. The approach can also be extended to branching structures with symbolic execution where the program paths are enumerated from the structure and each single path is checked at a time. The discussion of the branching structures is not included in the scope of this presentation.

This presentation further defines two distinct patterns of deadlock with their validation methods: circular dependency and orphaned receive. A circular dependency pattern may cause a program to deadlock if there exists a cycle among a group of processes where a receive on each member process waits for the issuing of a send on another member process but never gets a response. An orphaned receive pattern may cause a program to deadlock if there exists a pair of receives, both on the same process, one being a \emph{wildcard} (a receive that may match a send from any source) and the other being a \emph{deterministic} receive (a receive that only matches a send from a indicated source). The deadlock occurs when the runtime matches the wildcard receive to the send needed by the deterministic receive. 

This presentation presents how to detect all the instances for each of the patterns above by statically traversing the program. Further, this presentation presents how to validate the instances of the circular dependency pattern, by simply comparing the counts of issued operations, and how to validate instances of the orphaned receive pattern that requires a higher cost SMT encoding. The presentation first gives the pattern match algorithm and the validation algorithm for infinite buffer semantics. The modification to zero buffer semantics is discussed latter.  

The presentation includes proofs that the general algorithm is sound and complete for the patterns of circular dependency and orphaned receive. Also, the comparison with two state-of-art MPI verifiers shows that the new approach scales to large benchmark programs while other tools time out. The experiments further show that the two deadlock patterns in this presentation cover all the deadlock cases in benchmark programs.

%As a note, the algorithm is designed for infinite buffer semantics. Nevertheless, it is adaptable to zero buffer semantics with a few changes in deadlock validation.

The contributions are summarized as follows.
\begin{itemize}
\item The key contribution is an abstract machine that is able to efficiently prune provably non-feasible pattern instances from a set of potential deadlocks; 
\item The second contribution is the definition of two typical patterns: circular dependency and orphaned receive, and their validations; and
\item The third contribution is the implementation of the algorithm with a comparison to two state-of-art MPI verifiers over a set of benchmark programs. The comparison shows that the new approach scales to large benchmark programs while other tools time out.
\end{itemize}

%%add text such that these two patterns cover most deadlock situations. 

The rest of the paper is organized as follows: Sections 2 introduces the concurrent trace program for an MPI program; Section 3 presents the general algorithm in this presentation, Section 4 and 5 present the circular dependency pattern and the orphaned receive pattern with their pattern matching algorithms and their validation algorithms; Section 6 gives the experimental results; Section 7 discusses the related work; and Section 8 is the conclusion and future work.