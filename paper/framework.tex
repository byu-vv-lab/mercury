\section{Main Framework}

%%The general algorithm including three steps: Pattern Match, Feasible Check and Validation. The pseudocode needs to be revised so it shows each step. 


The main framework is presented in \algoref{algo:main}. The variable $\mathit{PT}$ is a set of pattern instances where each instance $\mathit{pt}$ is a set of receives. The function $\mathrm{PATTERNMATCH}$ at line 1 computes the 
%deadlock pattern or error pattern?
deadlock patterns given a \emph{ctp} and a set \emph{M} where each receive is associated with potential sends for which it might match. For convenience, the function $\mathit{M}(\mathtt{r_c}) = \{\mathtt{s_l}\mid(\mathtt{s_l},\mathtt{r_c})\in\mathit{M}\}$ returns all potential sends for the receive $\mathtt{r_c}$.  
The function $\mathrm{FEASIBLECHECK}$ at line 3 checks if there is a potential schedule for the pattern instance $\mathit{pt}$.  
The variables $\mathit{N_s}$ and $\mathit{N_r}$ represent the number of issued sends and the number of issued receives, respectively.
The algorithm continues to check other pattern instances if the set $\mathit{pt^\prime}$ is not empty indicating that no potential schedules exist. Otherwise, the algorithm further validates if a real error exists for $\mathit{pt}$ by the function $\mathrm{VALIDATE}$ at line 6. The algorithm aborts the verification process once an error is found at line 8 or repeats the steps for other pattern instances.
As a note, the algorithm is only applied to verifying programs under infinite buffer semantics. If the zero buffer semantics are enforced, the algorithm needs to be modified as discussed in Section 4 and Section 5. 
%The framework is useful for error detection with appropriate pattern match and validation algorithms. This paper applies the framework for deadlock detection based on two types of deadlock patterns in the next two sections.


\begin{algorithm}
\caption{Main Framework}\label{algo:main}
\begin{algorithmic}[1]
%\Procedure{Main Entrance}{}
%\Require $\mathit{ctp}$, a single-path MPI program
%\Require $\mathit{M}(\mathtt{r_c}) = \{\mathtt{s_l}\mid(\mathtt{s_l},\mathtt{r_c})\in\mathit{M}\}$, a set of potentially matched sends for $\mathtt{r_c}$
%\State  $\mathit{PT}$, a set of pattern instances
%\State  $\mathit{pt}$, a set of receives in the pattern instance $\mathit{pt}\in\mathit{PT}$
\State  $\mathit{PT} \gets$ \Call {PatternMatch}{$\mathit{ctp}$, $\mathit{M}$}
\For{$\mathit{pt} \in \mathit{PT}$}
\State ($\mathit{N_s}, \mathit{N_r}, \mathit{pt^\prime})\gets$\Call {FeasibleCheck}{$\mathit{pt}$, $\mathit{ctp}$}
\If{$\mathit{pt^\prime} \neq \emptyset$}
\State continue.
\ElsIf{$\neg$\Call {Validate}{$\mathit{N_s}, \mathit{N_r}, \mathit{pt}$}}
\State continue.
\Else\ report error and exit.
\EndIf

%\State ($\mathit{ctp}_s, \mathit{N_s}, \mathit{N_r}, \mathit{empty}_{pt}) \gets$ \Call {ScheduleFinder}{$\mathit{pt}$}
%\If{$\mathit{empty}_{pt}$} 
%\If{\Call{isCircular}{$\mathit{pt}$}}
%\For{$\mathtt{r_c}\in\mathit{pt}$}
%\State $\mathit{src} \gets$ source endpoint of $\mathtt{r_c}$, $\mathit{dest} \gets$ destination endpoint of $\mathtt{r_c}$
%\If{$\mathit{N_s}(\mathit{dest},\mathit{src}) > \mathit{N_r}(\mathit{dest},\mathit{src})$}
%\State \textbf{continue} \textit{point}
%\EndIf
%\EndFor
%\State report deadlock and exit.
%\EndIf
%\If{\Call {isMismatch}{$\mathit{pt}} \in$}
%\If{\textproc{SAT}({\Call {Encode}{$\mathit{ctp}_s$}})}
%\State report deadlock and exit.
%\EndIf
%\EndIf
%\EndIf
\EndFor
%\EndProcedure
\end{algorithmic}
\end{algorithm}

%%The feasible check and the soundness proof of feasible check (assuming pattern match is sound and validation is sound and complete)

The key insight of the framework is the function \textrm{FEASIBLECHECK} that is able to efficiently prune the schedules that are provably non-feasible. This function is presented as an abstract machine given by a term rewriting system using a \textit{CESK} style machine \footnote{The \textit{CESK} machine state is represented with a \textbf{C}ontrol string, \textbf{E}nvironment, \textbf{S}tore, and \textbf{K}ontinuation.}. \figref{fig:expr:stx}(b) defines the machine state and other syntax relating to evaluation. The machine state (\textit{st}) is a six-tuple of variables. The first variable \textit{ctp} defines the concurrent trace program. The set \epsnd\ maps a destination endpoint and a source endpoint to a number that is used to count issued sends. The variable \eprcv\ has the same structure only the number is used to count the number of matched receives. The variable \epwait\ records the pending receives by mapping the unique identifier of a nearest-enclosing wait to a set of the issued receives $\mathit{rcv}$. A nearest-enclosing wait is the first wait that witnesses the completion of a receive by indicating that the message is delivered and that all the previous receives on the same process issued earlier are complete as well. In this set, the action identifier, the source endpoint and the destination endpoint are recorded for each receive. The variable \epbarrier\ maps the unique identifier of a communicator to a number that is used to count the number of witnessed barriers.

\begin{figure*}[tb]
\centering
\scalebox{0.9}{
\mprset{flushleft}
\begin{mathpar}

\inferrule[Sndi Command]{
  \epsnd(v_{to},v_{frm}) = v_c \\ \epsnd^\prime = \epsnd[(v_{to},v_{frm}) \mapsto v_c +1] \\ 
  %\epsnd^{\prime\prime} = \epsnd^\prime[\forall v\ldotp \epsnd(v_{to},v) = v_i \mid (v_{to},v) \mapsto v_i +1] 
 \epsnd(v_{to},\ast) = v_i \\ \epsnd^{\prime\prime} = \epsnd^\prime[(v_{to},\ast) \mapsto v_i +1] 
}{
  ((\thread_0\ \ldots\ ((\sendi\ v_{frm}\ v_{to})\ \cmd_1\ \ldots\ \bot)\ \thread_2\ \ldots)\ \epsnd\ \eprcv\ \epwait\ \epbarrier\ \rcvp) \reduce{m}
  ((\thread_0\ \ldots\ (\cmd_1\ \ldots\ \bot)\ \thread_2\ \ldots)\ \epsnd^{\prime\prime}\ \eprcv\ \epwait\ \epbarrier\ \rcvp)
}

\and

\inferrule[Rcvi Command]{
 \epwait(\aid_w) =  ([\aid_1\ v_{frm1}\ v_{to1}]\ \ldots)
 \\ \epwait^\prime = \epwait [ \aid_w \mapsto ([\aid_0\ v_{frm0}\ v_{to0}]\ [\aid_1\ v_{frm1}\ v_{to1}]\ \ldots])] 
}{
  ((\thread_0\ \ldots\ ((\recvi\ \aid_0\ v_{frm0}\ v_{to0}\ \aid_w)\ \cmd_1\ \ldots\ \bot)\ \thread_2\ \ldots)\ \epsnd\ \eprcv\ \epwait\ \epbarrier\ \rcvp) \reduce{m}
  ((\thread_0\ \ldots\ (\cmd_1\ \ldots\ \bot)\ \thread_2\ \ldots)\ \epsnd\ \eprcv\ \epwait^\prime\ \epbarrier\ \rcvp)
}
\and
\inferrule[Wait (rcvi) Command 1]
{
  \epwait(\aid_w) = ()
}{
  ((\thread_0\ \ldots\ ((\wait\ \aid_w)\ \cmd_1\ \ldots\ \bot)\ \thread_2\ \ldots)\ \epsnd\ \eprcv\ \epwait\ \epbarrier\ \rcvp) \reduce{m}
  ((\thread_0\ \ldots\ (\cmd_1\ \ldots\ \bot)\ \thread_2\ \ldots)\ \epsnd\ \eprcv\ \epwait\ \epbarrier\ \rcvp)
}
\and
\inferrule[Wait (rcvi) Command 2]
{
   \epwait(\aid_w) = ([\aid_0\ v_{frm0}\ v_{to0}]\ [\aid_1\ v_{frm1}\ v_{to1}]\ \ldots) \\ \rcvp = (\aid_a\ \ldots\ \aid_0\ \aid_b\ \ldots) \\ \aid_0 \in \rcvp \\ \rcvp^\prime = (\aid_a\ \ldots\ \aid_b\ \ldots)
}{
  ((\thread_0\ \ldots\ ((\wait\ \aid_w)\ \cmd_1\ \ldots\ \bot)\ \thread_2\ \ldots)\ \epsnd\ \eprcv\ \epwait\ \epbarrier\ \rcvp) \reduce{m}
  ((\thread_0\ \ldots\ ((\wait\ \aid_w)\ \cmd_1\ \ldots\ \bot)\ \thread_2\ \ldots)\ \epsnd\ \eprcv\ \epwait\ \epbarrier\ \rcvp^\prime)
}
\and
\inferrule[Wait (rcvi) Command 3]
{
  \epwait(\aid_w) = ([\aid_0\ v_{frm0}\ v_{to0}]\ [\aid_1\ v_{frm1}\ v_{to1}]\ \ldots) \\
  \aid_0 \notin \rcvp \\ \eprcv(v_{to0},v_{frm0}) < \epsnd(v_{to0},v_{frm0}) \\ \eprcv(v_{to0},\ast) < \epsnd(v_{to0},\ast) \\
   \eprcv(v_{to0},v_{frm0}) = v_c \\
    \eprcv^\prime = \eprcv [(v_{to0}, v_{frm0}) \mapsto v_c + 1]] \\ 
    \epwait^\prime = \epwait [\aid_w\ \mapsto\ ([\aid_1\ v_{frm1}\ v_{to1}]\ \ldots)]
}{
  ((\thread_0\ \ldots\ ((\wait\ \aid_w)\ \cmd_1\ \ldots\ \bot)\ \thread_2\ \ldots)\ \epsnd\ \eprcv\ \epwait\ \epbarrier\ \rcvp) \reduce{m}
  ((\thread_0\ \ldots\ ((\wait\ \aid_w)\ \cmd_1\ \ldots\ \bot)\ \thread_2\ \ldots)\ \epsnd\ \eprcv^\prime\ \epwait^\prime\ \epbarrier\ \rcvp)
}
\and
\inferrule[Barrier Command 1]
{
  \epbarrier(\aid_0) = v_c \\ v_c < N_{proc} \\ \epbarrier^\prime = \epbarrier[\aid_0 \mapsto  v_c + 1]
}{
 ((\thread_0\ \ldots\ ((\barrier\ \aid_0)\ \cmd_1\ \ldots\ \bot)\ \thread_2\ \ldots)\ \epsnd\ \eprcv\ \epwait\ \epbarrier\ \rcvp) \reduce{m}
 ((\thread_0\ \ldots\ ((\barrier\ \aid_0)\ \cmd_1\ \ldots\ \bot)\ \thread_2\ \ldots)\ \epsnd\ \eprcv\ \epwait\ \epbarrier^\prime\ \rcvp)
}
\and
\inferrule[Barrier Command 2]
{
  \epbarrier(\aid_0) = N_{proc}
}{
 ((\thread_0\ \ldots\ ((\barrier\ \aid_0)\ \cmd_1\ \ldots\ \bot)\ \thread_2\ \ldots)\ \epsnd\ \eprcv\ \epwait\ \epbarrier\ \rcvp) \reduce{m}
 ((\thread_0\ \ldots\ (\cmd_1\ \ldots\ \bot)\ \thread_2\ \ldots)\ \epsnd\ \eprcv\ \epwait\ \epbarrier\ \rcvp)
}

\end{mathpar}}
\caption{Machine Reductions ($\reduce{m}$). }
\label{fig:machine}
\end{figure*}

A set of rewriting rules for the machine state is given in \figref{fig:machine}. These rules define how to execute a $\mathit{ctp}$ and determines whether or not a potential schedule exists for the pattern instance \textit{pt}. A potential schedule exists for \textit{pt} if all the receives in \textit{pt} are witnessed after the machine execution.
The \emph{Sndi Command} in \figref{fig:machine} consumes sends in any process of the $\mathit{ctp}$ if any exist. 
$\epsnd^\prime$\ is a new set, just like the old set $\epsnd$, only the new set maps the destination
endpoint $v_{to}$\ and the source endpoint $v_{frm}$ to the number $v_c + 1$ where $v_c$ is the content in the old set.
The set is also updated such that it maps $v_{to}$\ and $\ast$ to the number $v_i + 1$ where $v_i$ is the content in the old set. Note that the notation $\ast$ is a special source endpoint indicating any source.
The \emph{Rcvi Command} in \figref{fig:machine} consumes receives by updating the set \epwait. 
Similar to the rule \emph{Sndi Command}, \epwait\ merely adds a new record for the receive $x_0$ that is indexed by its nearest-enclosing wait. 
The \emph{Wait (Rcvi) Command} operates in three ways. 
If the wait $\aid_w$ maps to an empty set in \epwait\ indicating that no receives need to be completed by $\aid_w$, then $\aid_w$ is simply consumed. 
If the first receive $\aid_0$ in $\epwait(\aid_w)$ is stored in \rcvp\ where the notation $\in$ is used in this condition, then $\aid_0$ is removed indicating that it is witnessed. 
%As a note, \algoref{algo:main} checks if all the receives in \rcvp\ are witnessed after detecting a schedule for $\mathit{pt}$. 
The last way that a wait can move forward checks whether the first receive $\aid_0$\ in $\epwait(x_w)$ is able to be consumed. Note that the receives in $\epwait(\aid_0)$ are ordered as they are on the original process of the $\mathit{ctp}$. 
Therefore, if the first receive in $\epwait(x_w)$ cannot be consumed, the following receives are blocked as well. 
This step requires two conditions. First, $\aid_0$ is not a receive in the pattern instance \rcvp\ where the notation $\notin$ is used in this condition. Second, there are more sends than receives with common source and destination endpoints and there are more sends for the preceding wildcard receives. If both conditions are satisfied, then the set \eprcv\ is updated where the new set maps the destination endpoint $v_{to}$\ and the source endpoint $v_{frm}$ to the number $v_c + 1$ where $v_c$ is the content in the old set. $\aid_0$ is then removed from \epwait. 
The \emph{Barrier Command} moves the barrier forward by its synchronization rule. It is assumed that the group of any barrier consists of all the processes in $\mathit{ctp}$. 
If the count of the witnessed barriers $\epbarrier(\aid_0)$ for a specific communicator $\aid_0$ is less than the size of the processes $N_{proc}$ indicating that the barriers for $\aid_0$ are not matched, then the barrier is not consumed and $\epbarrier(\aid_0)$ is incremented. The barrier can only be consumed if the count $\epbarrier(\aid_0)$ is equal to $N_{proc}$.

The machine rewrites the state until no more reduction rules can be applied indicating that there is no way to further traverse the program. The first statement that cannot be consumed on any process is either the bottom of the process or a blocking operation. A blocking operation could be a wait or a barrier. 

%%Soundness Proof needs to be revised such that it shows the feasible check (operational semantics) is sound.
The following proof presents that the abstract machine in \figref{fig:machine} is complete assuming the function \textrm{PATTERNMATCH} detects all the instances for a particular pattern. This assumption is proved for the circular dependency pattern and the orphaned receive pattern in Section 4 and Section 5, respectively. 

\begin{lemma}[Completeness for Feasible Check]
For any single-path MPI program, \textit{ctp}, any feasible schedule for a deadlock pattern instance is demonstrated by the function \textrm{FEASIBLECHECK} in \algoref{algo:main}. 
\label{lemma:complete}
\end{lemma}
\begin{proof}
Proof by showing that the abstract machine in \figref{fig:machine} simulate the message communication under infinite buffer semantics. For \emph{Sndi Command} and \emph{Rcvi Command}, a send or receive is consumed immediately by incrementing two structures $\mathit{N_s}$ and $\mathit{N_r}$, respectively. This is consistent with the issuing of send and receive under infinite buffer semantics. The three cases of \emph{Wait Command} witness the completion of the receives that are not in the pattern $\mathit{pt}$ and intend to get to the receives in $\mathit{pt}$. The two cases of \emph{Barrier Command} block the execution of a member process until all the barriers in group are witnessed. Since the abstract machine in \figref{fig:machine} are able to simulate the behavior for infinite buffer semantics, any feasible schedule should be demonstrated by executing \textit{ctp} on the machine.
\end{proof}
